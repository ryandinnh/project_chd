{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaxdSH2gHIV4tRg2/oCkkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryandinnh/project_chd/blob/main/conclusion_part.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "###Comparison of different models\n",
        "In general, lower values of SSE, MSE and RMSE are more desirable since they indicate better predictive accuracy, while higher values of R^2 imply a better fit of the model to the data.\n",
        "\n",
        "Based on the results we got, the LR model has the lowest SSE, MSE and RMSE, and it also has the highest R^2, suggesting LR can be the comparable best model in these three (indicating better predictive accuracy and better explanation in a larger proportion of the variance in the target variable).\n",
        "\n",
        "Besides, we also tried to impute medians/means into dataset considering there were a lot of null values. Surprisingly, the cleaning process didn't enhance any of the models, except for linear regression, which showed only a slight improvement with median imputation on the variables we addressed.\n",
        "\n",
        "Interestingly, the decision tree model's performance notably deteriorated with imputation compared to simply dropping all N/A values.\n",
        "\n",
        "Considering the results did not improve clearly and imputing did not always make things more accurate, we decided to use our first version of cleaning dataset without imputing median/mean values.\n",
        "\n",
        "###Data Limitation\n",
        "Missing data and Non-response bias\n",
        "\n",
        "* The total drawn sample was 6,537. In the end, only 4,494 or 68.8 per cent of the drawn sample came to the study clinic for examination in spite of many and varied appealed to nonrespondents\n",
        "\n",
        "* Sometimes, people prefer not to present some specific type of data, especially those who got some illness prefer not to release their health issue data. Also, physical death of people also led to non-response. Non-response bias affects the data result, undermining the validity and generalizability of study findings. Sometimes, it is also linked to survivorship bias.\n",
        "\n",
        "Sampling bias/ Lack of population diversity\n",
        "\n",
        "* According to the study background, the study team tried a lot to reduce self-selection bias or sampling bias. However, because of cost, effectiveness and maneuverability, the study focused on people between 30-59 in only one town.\n",
        "\n",
        "* Geographic coverage inherently constrains the extent to which we can draw general conclusions. It is plausible that certain communities within the United States markedly diverge from the norm concerning arteriosclerosis and hypertension. Conversely, within the white race in the U.S., the variability in arteriosclerosis and hypertension distribution within communities likely surpasses that between communities. Thus, a diverse array of circumstances influencing the onset of these diseases may exist within any given community. This variability may significantly impact the accuracy and generality of our models, as they must adequately account for the diverse factors influencing disease development across different communities and populations.\n",
        "\n",
        "###Research strategy evaluation and possible improvements\n",
        "\n",
        "* The strategy of this study/research can be improved and developed\n",
        "Considering about the current techniques and financial/academic support, this study could be redone within a more diversified population with a bigger sample, a larger age gap, more races, more ethics, more geographic backgrounds.\n",
        " - The collection of data can be easier and more efficient and updated though\n",
        "using updated techniques without making people feel worried about info privacy. It is reasonable to think about some of the non-responses led by the unwillingness about possible privacy leak, especially about someoneâ€™s healthiness.\n",
        "\n",
        " - The study teams can try to engage with more communities in different locations to have an extension of geographic.\n",
        "\n",
        " - Keep continuously tracking participants in a longer period helps to offer more insightful views of long-term effects.\n",
        "\n",
        " - Intentionally select samples with more races/ethics so that we can increase our generality of conclusion."
      ],
      "metadata": {
        "id": "aaKdeKvbKumV"
      }
    }
  ]
}